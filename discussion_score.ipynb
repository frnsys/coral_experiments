{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a gamma/Poisson Bayesian model since gamma is a conjugate prior for Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discussion_score(threads, alpha=1, beta=2):\n",
    "    # alpha and beta are priors for the gamma prior\n",
    "    # see below for more info\n",
    "    \n",
    "    X = np.array([t.length for t in threads])\n",
    "    n = len(X)\n",
    "\n",
    "    # this is the posterior mean (i.e. the expected lambda parameter for the poisson)\n",
    "    # which is also the expected value for the poisson distribution itself\n",
    "    # since the gamma distribution is a conjugate prior for the poisson,\n",
    "    # we get this mean analytically\n",
    "    return ((n/(n + beta)) * (np.sum(X)/n)) + (beta/(n+beta) * (alpha/beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Thread():\n",
    "    # dummy class to represent threads\n",
    "    def __init__(self, length):\n",
    "        self.length = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1: 2.33333333333\n",
      "score 2: 1.88888888889\n",
      "score 3: 5.33333333333\n",
      "score 4: 6.83333333333\n",
      "score 5: 7.88888888889\n",
      "score 6: 9.18181818182\n"
     ]
    }
   ],
   "source": [
    "# small comments section, with mostly single comments, but one longer thread\n",
    "threads = [Thread(10), Thread(1), Thread(1), Thread(1)]\n",
    "score_1 = discussion_score(threads)\n",
    "print('score 1:', score_1)\n",
    "\n",
    "# a longer comments section, with mostly single comments, but one longer thread\n",
    "threads = [Thread(10), Thread(1), Thread(1), Thread(1), Thread(1), Thread(1), Thread(1)]\n",
    "score_2 = discussion_score(threads)\n",
    "print('score 2:', score_2)\n",
    "\n",
    "# a larger sample size with more short threads should lower the score\n",
    "assert(score_2 < score_1)\n",
    "\n",
    "# more longer threads should have a higher score\n",
    "threads = [Thread(10), Thread(10), Thread(10), Thread(1)]\n",
    "score_3 = discussion_score(threads)\n",
    "print('score 3:', score_3)\n",
    "assert(score_3 > score_1)\n",
    "\n",
    "# only longer threads should have an even higher score\n",
    "threads = [Thread(10), Thread(10), Thread(10), Thread(10)]\n",
    "score_4 = discussion_score(threads)\n",
    "print('score 4:', score_4)\n",
    "assert(score_4 > score_3)\n",
    "\n",
    "# more threads should make us more confident in the score\n",
    "threads = [Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10)]\n",
    "score_5 = discussion_score(threads)\n",
    "print('score 5:', score_5)\n",
    "assert(score_5 > score_4)\n",
    "\n",
    "# more threads should make us more confident in the score\n",
    "# lower beta should give higher score (see below for more info)\n",
    "threads = [Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10), Thread(10)]\n",
    "score_6 = discussion_score(threads, beta=1)\n",
    "print('score 6:', score_6)\n",
    "assert(score_6 > score_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1 4.06663251352\n",
      "score 2 5.25\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class Thread():\n",
    "    # dummy class to represent threads\n",
    "    def __init__(self, length, participants):\n",
    "        self.length = length\n",
    "        self.participants = participants\n",
    "\n",
    "# need to also take into account number of particiants - a better discussion is one with more people involved\n",
    "threads = [Thread(10, 2), Thread(10, 10)]\n",
    "mean_participant_ratio = np.mean([t.participants/t.length for t in threads])\n",
    "score = discussion_score(threads)\n",
    "score_1 = math.sqrt(mean_participant_ratio) * score\n",
    "print('score 1', score_1)\n",
    "\n",
    "threads = [Thread(10, 10), Thread(10, 10)]\n",
    "mean_participant_ratio = np.mean([t.participants/t.length for t in threads])\n",
    "score = discussion_score(threads)\n",
    "score_2 = math.sqrt(mean_participant_ratio) * score\n",
    "print('score 2', score_2)\n",
    "\n",
    "# threads of same length, but with more participants, should have a higher score\n",
    "assert(score_2 > score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the gamma distribution to give us a value which we use as $\\lambda$, which is the parameter (and mean aka expected value) for the poisson distribution we assume describes thread counts in a comments section. We use the expected value from the gamma distribution as $\\lambda$.\n",
    "\n",
    "In this context, $\\lambda$ is a prediction for thread length given a comments section. That is, it tells us: if a new thread is started in this comments section, how long do we expect it to be? We expect it to be longer if an article is generating more discussion.\n",
    "\n",
    "The expected value for a gamma distribution is just $\\alpha \\beta$.\n",
    "\n",
    "So if we set $\\alpha = 1, \\beta = 2$, then the prior value for $\\lambda = \\alpha \\beta = 2$, which means that by default, in an empty comments section, we expect the first thread to have at least two comments in it. We can scale this back and more conservatively estimate that the first thread will have only one comment by setting $\\alpha = 1, \\beta = 1$, so that the prior $\\lambda = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2.00539740578\n"
     ]
    }
   ],
   "source": [
    "# just to computationally demonstrate that alpha * beta is indeed the expected value for the gamma distribution\n",
    "\n",
    "alpha = 1\n",
    "beta = 2\n",
    "\n",
    "# expected gamma value is alpha * beta\n",
    "expected_1 = alpha * beta\n",
    "\n",
    "# can also compute the expected value by simulation\n",
    "samples = np.random.gamma(alpha, beta, size=100000)\n",
    "expected_2 = np.mean(samples)\n",
    "\n",
    "print(expected_1)\n",
    "print(expected_2)\n",
    "\n",
    "# these two should be very close\n",
    "assert(abs(expected_1 - expected_2) < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4.0004\n"
     ]
    }
   ],
   "source": [
    "# doing the same for poisson\n",
    "lmbda = 4\n",
    "\n",
    "expected_1 = lmbda\n",
    "samples = np.random.poisson(lmbda, size=100000)\n",
    "expected_2 = np.mean(samples)\n",
    "\n",
    "print(expected_1)\n",
    "print(expected_2)\n",
    "\n",
    "# these two should be very close\n",
    "assert(abs(expected_1 - expected_2) < 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying it with cython~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "def cy_discussion_score(np.ndarray threads, float alpha=1, float beta=2):\n",
    "    cdef int n = len(threads)\n",
    "    return ((n/(n + beta)) * (np.sum(threads)/n)) + (beta/(n+beta) * (alpha/beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def py_discussion_score(threads, alpha=1, beta=2):\n",
    "    n = len(threads)\n",
    "    return ((n/(n + beta)) * (np.sum(threads)/n)) + (beta/(n+beta) * (alpha/beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 14.94 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100000 loops, best of 3: 7.3 µs per loop\n",
      "The slowest run took 5.33 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100000 loops, best of 3: 7.65 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit cy_discussion_score(np.array([1,2,4,4,4,4,4,4,4]), 1, 2)\n",
    "%timeit py_discussion_score(np.array([1,2,4,4,4,4,4,4,4]), 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Maybe rather than thread length, it is better to try and predict the number of unique participants a thread will have. Can use the same function as above, just assume that `Thread.length` is the number of unique participants instead.\n",
    "\n",
    "Could also use the original thread length score but combine it with \"what is the probability that the next speaker in a thread is a new participant?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def differing_dyads(thread):\n",
    "    # count the number of dyads with two different participants\n",
    "    # and count the number of total dyads\n",
    "    n_pairs = 0\n",
    "    n_diff_participant = 0\n",
    "\n",
    "    for a, b in zip(thread, thread[1:]):\n",
    "        n_pairs += 1\n",
    "        if a != b:\n",
    "            n_diff_participant += 1\n",
    "\n",
    "    return n_diff_participant, n_pairs\n",
    "\n",
    "# A thread with participant ids:\n",
    "thread = [0,1,0,1,2,1,1,1]\n",
    "diff, total = differing_dyads(thread)\n",
    "print(diff/total)\n",
    "\n",
    "thread = [0,0,0,0,0,0,0,0]\n",
    "diff, total = differing_dyads(thread)\n",
    "print(diff/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO build a model around the above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
